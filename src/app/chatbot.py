import streamlit as st
import os
from dotenv import load_dotenv
from tools import retrieve_movies, search_movies_by_filters
from prompt import rag_prompt
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_classic.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from vector_store import get_retriever
import warnings

warnings.filterwarnings("ignore")
load_dotenv()

st.set_page_config(
    page_title="üé¨ Movie Recommender RAG",
    page_icon="üé¨",
    layout="wide"
)

# CSS personnalis√©
st.markdown("""
    <style>
    .stAlert {
        padding: 1rem;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)

st.title("üé¨ Movie Recommender avec Graph RAG")
st.caption("Syst√®me de recommandation utilisant Neo4j et embeddings vectoriels")

# Initialisation de la session
if "messages_agent" not in st.session_state:
    st.session_state["messages_agent"] = [
        {
            "role": "assistant", 
            "content": "üé¨ Bonjour! Je suis votre assistant cin√©ma intelligent. Je peux vous recommander des films bas√©s sur vos pr√©f√©rences!\n\n**Exemples de questions:**\n- Recommande-moi un film d'action avec des effets sp√©ciaux\n- Quels films de Christopher Nolan ont une note > 8?\n- Films de science-fiction philosophiques\n- Films d'horreur r√©cents bien not√©s"
        }
    ]

# Initialisation de l'agent
if "agent" not in st.session_state:
    with st.spinner("üîÑ Initialisation de l'agent et du vector store Neo4j..."):
        try:
            # Initialisation du Neo4jVector store
            retriever = get_retriever(use_existing=True)
            
            if retriever is None:
                st.error("‚ùå Impossible d'initialiser le vector store. V√©rifiez votre connexion Neo4j.")
                st.stop()
            
            # Initialisation du LLM
            google_key = os.environ.get("GOOGLE_API_KEY")
            if not google_key:
                st.error("‚ùå GOOGLE_API_KEY non trouv√©e dans .env")
                st.stop()
            
            llm = ChatGoogleGenerativeAI(
                model="gemini-2.5-flash",
                convert_system_message_to_human=True,
                temperature=0.7
            )
            
            # Outils disponibles
            tools = [retrieve_movies, search_movies_by_filters]
            
            # Prompt de l'agent
            prompt = ChatPromptTemplate.from_messages([
                ("system", rag_prompt()),
                ("human", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ])
            
            # Cr√©ation de l'agent
            agent = create_tool_calling_agent(llm, tools, prompt)
            st.session_state["agent"] = AgentExecutor(
                agent=agent, 
                tools=tools, 
                verbose=True,
                handle_parsing_errors=True
            )
            
            st.success("‚úÖ Agent initialis√© avec succ√®s!")
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'initialisation: {str(e)}")
            st.exception(e)
            st.stop()

# Affichage de l'historique
for msg in st.session_state.messages_agent:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input utilisateur
if prompt := st.chat_input("üé¨ Quelle sorte de film cherchez-vous?"):
    # Ajouter le message utilisateur
    st.session_state.messages_agent.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # G√©n√©rer la r√©ponse
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        
        try:
            with st.spinner("ü§î Recherche en cours..."):
                response = st.session_state["agent"].invoke({"input": prompt})
                
                full_response = response["output"]
                
                response_placeholder.markdown(full_response)
                
                st.session_state.messages_agent.append({
                    "role": "assistant",
                    "content": full_response
                })
                
        except Exception as e:
            error_message = f"‚ùå Erreur lors de la g√©n√©ration: {str(e)}"
            response_placeholder.error(error_message)
            st.session_state.messages_agent.append({
                "role": "assistant",
                "content": error_message
            })

# Sidebar
with st.sidebar:
    st.header("‚ÑπÔ∏è Informations")
    
    st.markdown("""
    **üîß Composants:**
    - üß† LLM: Gemini 2.0 Flash
    - üóÑÔ∏è Base: Neo4j
    - üìä Vector Store: Neo4jVector
    - üîç Embeddings: MiniLM-L6-v2
    
    **üõ†Ô∏è Outils disponibles:**
    - `retrieve_movies`: Recherche s√©mantique
    - `search_movies_by_filters`: Filtres pr√©cis
    """)
    
    st.divider()
    
    # Stats (si possible)
    try:
        retriever = get_retriever()
        if retriever:
            st.markdown("**üìä Statistiques:**")
            st.info("Vector store: ‚úÖ Connect√©")
    except:
        st.warning("‚ö†Ô∏è Stats non disponibles")
    
    st.divider()
    
    # Bouton reset
    if st.button("üóëÔ∏è Effacer l'historique", use_container_width=True):
        st.session_state.messages_agent = [
            {
                "role": "assistant", 
                "content": "üé¨ Historique effac√©! Posez-moi de nouvelles questions sur les films."
            }
        ]
        st.rerun()
    
    st.divider()
    
    # Exemples de requ√™tes
    st.markdown("**üí° Exemples de questions:**")
    example_queries = [
        "Films d'action des ann√©es 2010",
        "Christopher Nolan note > 8",
        "Science-fiction philosophique",
        "Com√©dies romantiques bien not√©es"
    ]
    
    for query in example_queries:
        if st.button(f"üìù {query}", use_container_width=True):
            st.session_state.messages_agent.append({"role": "user", "content": query})
            st.rerun()